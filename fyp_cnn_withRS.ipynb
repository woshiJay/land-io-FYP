{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_image(image_path, size=(224, 224)):\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Quality enhancement\n",
    "    enhancer = ImageEnhance.Sharpness(img)\n",
    "    img = enhancer.enhance(2.0)  # Increase sharpness\n",
    "    \n",
    "    # Noise reduction\n",
    "    image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Consistency\n",
    "    img = img.resize(size, Image.LANCZOS)\n",
    "    \n",
    "    # Canny edge detection\n",
    "    image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    img = Image.fromarray(edges)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Apply preprocessing and save to new directory\n",
    "input_dir = 'images'\n",
    "output_dir = 'processed_images'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for category in os.listdir(input_dir):\n",
    "    category_path = os.path.join(input_dir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        output_category_path = os.path.join(output_dir, category)\n",
    "        if not os.path.exists(output_category_path):\n",
    "            os.makedirs(output_category_path)\n",
    "        for image_name in os.listdir(category_path):\n",
    "            image_path = os.path.join(category_path, image_name)\n",
    "            preprocessed_img = preprocess_image(image_path)\n",
    "            preprocessed_img.save(os.path.join(output_category_path, image_name))\n",
    "\n",
    "train_dir = 'images_train_test_val/train'\n",
    "validation_dir = 'images_train_test_val/validation'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# change to testing\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', init_mode='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu', kernel_initializer=init_mode))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer=init_mode))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer=init_mode))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(21, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'model__num_filters': [32, 64, 128],\n",
    "    'model__kernel_size': [3, 5],\n",
    "    'model__pool_size': [2, 3],\n",
    "    'model__dropout_rate': [0.25, 0.5],\n",
    "    'epochs': [10, 20],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2)\n",
    "random_search_result = random_search.fit(train_generator, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and results\n",
    "best_params = random_search_result.best_params_\n",
    "best_score = random_search_result.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best model for evaluation\n",
    "best_model = random_search_result.best_estimator_.model\n",
    "train_loss, train_acc = best_model.evaluate(train_generator)\n",
    "val_loss, val_acc = best_model.evaluate(validation_generator)\n",
    "\n",
    "print(f'Train accuracy: {train_acc:.4f}, Validation accuracy: {val_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
