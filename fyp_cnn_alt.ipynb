{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:  \n",
    "    # path defination\n",
    "    class Path:\n",
    "        train_df = 'data/images_train_test_val/train'\n",
    "        val_df = 'data/images_train_test_val/val'\n",
    "        test_df = 'data/images_train_test_val/test'\n",
    "        image_folder = 'data/images'\n",
    "        model_save_path = 'working/weights'\n",
    "        tensorboard_logs_path = \"working/tensorboard/logs\"\n",
    "        figure_save_path = \"working/Figures\"\n",
    "        \n",
    "    # dataset parameter\n",
    "    class Dataset:\n",
    "        batch_size = 64\n",
    "        img_size = (64, 64)\n",
    "        buffer_size = 1000\n",
    "    \n",
    "    class HyperParameter:\n",
    "        batch_size = 64\n",
    "        learning_rate = 0.0001\n",
    "        input_shape = (64, 64, 3)\n",
    "        num_classes = 10\n",
    "        epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class EuroSatLoader:\n",
    "    def __init__(self, csv_path, image_folder, batch_size = 32, img_size = (32, 32), buffer_size = 100, shuffle = True):\n",
    "        self.csv_path = csv_path\n",
    "        self.image_folder = image_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        # Load the CSV files using pandas\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "        # Create a list of image paths and labels for train, validation, and test datasets\n",
    "        self.image_paths = [os.path.join(self.image_folder, filename) for filename in self.df.Filename] \n",
    "        self.labels = self.df.Label.values\n",
    "        \n",
    "    def load_image(self, image_path, label):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3) #\n",
    "        image = tf.image.resize(image, self.img_size)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        return image, label\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.image_paths, self.labels))\n",
    "        dataset = dataset.map(self.load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=self.buffer_size, reshuffle_each_iteration=True)\n",
    "        dataset = dataset.batch(batch_size=self.batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class BaselineCNN:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        inputs = tf.keras.layers.Input(shape=self.input_shape)\n",
    "        x = tf.keras.layers.Conv2D(32, (3,3), activation='relu',padding='same')(inputs)\n",
    "        x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
    "        x = tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
    "        x = tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
    "        x = tf.keras.layers.Dropout(0.3) (x)\n",
    "        x = tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
    "        x = tf.keras.layers.Dropout(0.3) (x)\n",
    "        x = tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
    "        x = tf.keras.layers.Conv2D(32, (3,3), activation='relu',padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        outputs = tf.keras.layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def compile(self, learning_rate):\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, train_data, val_data, epochs, batch_size, model_save_path, log_dir):\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(model_save_path + 'best_model.h5', monitor='val_loss', mode='min', save_weights_only=True,save_best_only=True, verbose=1)\n",
    "        tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "        callbacks = [early_stop, checkpoint, tensorboard]\n",
    "        history = self.model.fit(train_data, \n",
    "                                 epochs=epochs,\n",
    "                                 batch_size=batch_size, \n",
    "                                 validation_data=val_data, \n",
    "                                 callbacks=callbacks)\n",
    "        return history\n",
    "    def evaluate(self, data):\n",
    "        loss, accuracy = self.model.evaluate(data)\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return self.model.predict(data)\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        self.model.load_weights(model_path)\n",
    "        \n",
    "    def plot_model_architecture(self, file_path):\n",
    "        tf.keras.utilsplot_model(self, to_file=file_path, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "class ModelUtils:\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_cm(y_true, y_pred, class_names,save_path, figsize=(10,10)):\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "        cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "        cm_perc = cm / cm_sum.astype(float) * 100\n",
    "        annot = np.empty_like(cm).astype(str)\n",
    "        nrows, ncols = cm.shape\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                c = cm[i, j]\n",
    "                p = cm_perc[i, j]\n",
    "                if i == j:\n",
    "                    s = cm_sum[i]\n",
    "                    annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "                elif c == 0:\n",
    "                    annot[i, j] = ''\n",
    "                else:\n",
    "                    annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "        # cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "        cm = pd.DataFrame(cm, index=[i for i in class_names],\n",
    "                    columns = [i for i in class_names])\n",
    "        \n",
    "        cm.index.name = 'True label'\n",
    "        cm.columns.name = 'Predicted label'\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
    "        plt.savefig(save_path+'confusion_matrix.png')\n",
    "        \n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "        ax = plt.subplot()\n",
    "        sns.heatmap(cm, annot=True, ax=ax, cmap='Blues', fmt='g')\n",
    "        ax.set_xlabel('Predicted labels')\n",
    "        ax.set_ylabel('True labels')\n",
    "        ax.set_title('Confusion Matrix')\n",
    "        ax.xaxis.set_ticklabels(labels)\n",
    "        ax.yaxis.set_ticklabels(labels)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def plot_loss_accuracy(save_path,history):\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax[0].plot(history.history['loss'], label='train')\n",
    "        ax[0].plot(history.history['val_loss'], label='validation')\n",
    "        ax[0].set_xlabel('Epoch')\n",
    "        ax[0].set_ylabel('Loss')\n",
    "        ax[0].set_title('Loss vs Epoch')\n",
    "        ax[0].legend()\n",
    "        ax[1].plot(history.history['accuracy'], label='train')\n",
    "        ax[1].plot(history.history['val_accuracy'], label='validation')\n",
    "        ax[1].set_xlabel('Epoch')\n",
    "        ax[1].set_ylabel('Accuracy')\n",
    "        ax[1].set_title('Accuracy vs Epoch')\n",
    "        ax[1].legend()\n",
    "        plt.savefig(save_path+'loss_accuracy_curve.png')\n",
    "        plt.show()\n",
    "\n",
    "    # function for scoring roc auc score for multi-class\n",
    "    @staticmethod\n",
    "    def multiclass_roc_auc_score(y_true, model_predicted_label,class_names,save_path, average=\"macro\"):\n",
    "        fig, c_ax = plt.subplots(1,1, figsize = (16, 16))\n",
    "        lb = LabelBinarizer()\n",
    "        lb.fit(y_true)\n",
    "        y_test = lb.transform(y_true)\n",
    "        y_pred = lb.transform(model_predicted_label)\n",
    "        \n",
    "        for (idx, c_label) in enumerate(class_names):\n",
    "            fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "            c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "        c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
    "        \n",
    "        c_ax.legend()\n",
    "        c_ax.set_xlabel('False Positive Rate')\n",
    "        c_ax.set_ylabel('True Positive Rate')\n",
    "        plt.savefig(save_path+'roc_auc_curve.png')\n",
    "        plt.show()\n",
    "        return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cfg = CFG()\n",
    "    Path(cfg.Path.model_save_path).mkdir(parents = True, exist_ok = True)\n",
    "    Path(cfg.Path.tensorboard_logs_path).mkdir(parents = True, exist_ok = True)\n",
    "    Path(cfg.Path.figure_save_path).mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    train_loader = EuroSatLoader(csv_path = cfg.Path.train_df, \n",
    "                                image_folder = cfg.Path.image_folder,\n",
    "                                batch_size = cfg.Dataset.batch_size,\n",
    "                                img_size = cfg.Dataset.img_size,\n",
    "                                buffer_size = cfg.Dataset.buffer_size, \n",
    "                                shuffle = True)\n",
    "    train_dataset = train_loader.get_dataset()\n",
    "\n",
    "    # print(\"Train Dataset\")\n",
    "    # for i, (x, y) in enumerate(train_dataset):\n",
    "    #     print(x.shape, y.shape)\n",
    "    #     if i == 10:\n",
    "    #         break\n",
    "\n",
    "    val_loader = EuroSatLoader(csv_path = cfg.Path.val_df, \n",
    "                                image_folder = cfg.Path.image_folder,\n",
    "                                batch_size = cfg.Dataset.batch_size,\n",
    "                                img_size = cfg.Dataset.img_size,\n",
    "                                buffer_size = cfg.Dataset.buffer_size, \n",
    "                                shuffle = False)\n",
    "    val_dataset = val_loader.get_dataset()\n",
    "    test_loader = EuroSatLoader(csv_path = cfg.Path.test_df, \n",
    "                                image_folder = cfg.Path.image_folder,\n",
    "                                batch_size = cfg.Dataset.batch_size,\n",
    "                                img_size = cfg.Dataset.img_size,\n",
    "                                buffer_size = cfg.Dataset.buffer_size, \n",
    "                                shuffle = False)\n",
    "    test_dataset = test_loader.get_dataset()\n",
    "    \n",
    "    model = BaselineCNN(input_shape = cfg.HyperParameter.input_shape, \n",
    "                        num_classes = cfg.HyperParameter.num_classes)\n",
    "    \n",
    "    print(f\"INFO ===========Training Started===============\")\n",
    "    model.compile(learning_rate= cfg.HyperParameter.learning_rate)\n",
    "    history = model.train(train_data = train_dataset, \n",
    "                          val_data = val_dataset,\n",
    "                          epochs = cfg.HyperParameter.epochs,\n",
    "                          batch_size= cfg.HyperParameter.batch_size, \n",
    "                          model_save_path= cfg.Path.model_save_path,\n",
    "                          log_dir= cfg.Path.tensorboard_logs_path)\n",
    "    print(f\"INFO ===========Training Finished===============\")\n",
    "    print(f\"INFO ===========Plot Curve===============\")\n",
    "    ModelUtils.plot_loss_accuracy(cfg.Path.figure_save_path,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_model('working/weights/best_model.h5')\n",
    "\n",
    "train_loss, train_acc = model.evaluate(train_dataset)\n",
    "print(f\"train_loss:{train_loss}:: train_accuracy: {train_acc}\")\n",
    "\n",
    "val_loss, val_acc = model.evaluate(val_dataset)\n",
    "print(f\"val_loss:{val_loss}:: val_acc: {val_acc}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"test_loss:{test_loss}:: test_acc: {test_acc}\")\n",
    "    \n",
    "predictions = model.predict(test_dataset)\n",
    "predicted_label = np.argmax(predictions, axis = 1)\n",
    "\n",
    "class_names = [\"Agricultural\",\"Airplane\",\"Baseball Diamond\",\"Beach\",\"Buildings\",\n",
    "                \"Chaparral\",\"Dense Residential\",\"Forest\",\"Freeway\",\"Golf Course\",\n",
    "                \"Harbor\",\"Intersection\",\"Medium Residential\",\"Mobile Home Park\",\n",
    "                \"Overpass\",\"Parking Lot\",\"River\",\"Runway\",\"Sparse Residential\",\n",
    "                \"Storage Tanks\",\"Tennis Court\"]\n",
    "\n",
    "true_labels = []\n",
    "for image, label in test_dataset: #.as_numpy_iterator()\n",
    "    true_labels += list(label.numpy())\n",
    "\n",
    "# Plot confusion Matrix\n",
    "ModelUtils.plot_cm(y_true = true_labels, y_pred = predicted_label, class_names = class_names,save_path=cfg.Path.figure_save_path)\n",
    "#Plot Roc Auc Curve\n",
    "ModelUtils.multiclass_roc_auc_score(y_true= true_labels, model_predicted_label= predicted_label,class_names = class_names,save_path=cfg.Path.figure_save_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
