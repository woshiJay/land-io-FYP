{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from PIL import Image, ImageEnhance\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(category_path):\n\u001b[1;32m     38\u001b[0m             image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(category_path, image_name)\n\u001b[0;32m---> 39\u001b[0m             preprocessed_img \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m             preprocessed_img\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_category_path, image_name))\n\u001b[1;32m     42\u001b[0m train_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages_train_test_val/train\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path, size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)):\n\u001b[0;32m----> 3\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Quality enhancement\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     enhancer \u001b[38;5;241m=\u001b[39m ImageEnhance\u001b[38;5;241m.\u001b[39mSharpness(img)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_m1_env/lib/python3.10/site-packages/PIL/Image.py:3286\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3283\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3284\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3286\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3288\u001b[0m preinit()\n\u001b[1;32m   3290\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_image(image_path, size=(224, 224)):\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Quality enhancement\n",
    "    enhancer = ImageEnhance.Sharpness(img)\n",
    "    img = enhancer.enhance(2.0)  # Increase sharpness\n",
    "    \n",
    "    # Noise reduction\n",
    "    image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Consistency\n",
    "    img = img.resize(size, Image.LANCZOS)\n",
    "    \n",
    "    # Canny edge detection\n",
    "    image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    img = Image.fromarray(edges)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Apply preprocessing and save to new directory\n",
    "input_dir = 'images'\n",
    "output_dir = 'processed_images'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for category in os.listdir(input_dir):\n",
    "    category_path = os.path.join(input_dir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        output_category_path = os.path.join(output_dir, category)\n",
    "        if not os.path.exists(output_category_path):\n",
    "            os.makedirs(output_category_path)\n",
    "        for image_name in os.listdir(category_path):\n",
    "            image_path = os.path.join(category_path, image_name)\n",
    "            preprocessed_img = preprocess_image(image_path)\n",
    "            preprocessed_img.save(os.path.join(output_category_path, image_name))\n",
    "\n",
    "train_dir = 'images_train_test_val/train'\n",
    "test_dir = 'images_train_test_val/test'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', init_mode='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu', kernel_initializer=init_mode))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer=init_mode))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer=init_mode))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(21, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'model__num_filters': [32, 64, 128],\n",
    "    'model__kernel_size': [3, 5],\n",
    "    'model__pool_size': [2, 3],\n",
    "    'model__dropout_rate': [0.25, 0.5],\n",
    "    'epochs': [10, 20],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2)\n",
    "random_search_result = random_search.fit(train_generator, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and results\n",
    "best_params = random_search_result.best_params_\n",
    "best_score = random_search_result.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best model for evaluation\n",
    "best_model = random_search_result.best_estimator_.model\n",
    "train_loss, train_acc = best_model.evaluate(train_generator)\n",
    "val_loss, val_acc = best_model.evaluate(validation_generator)\n",
    "\n",
    "print(f'Train accuracy: {train_acc:.4f}, Validation accuracy: {val_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
